{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1CUmXEtPyBw6",
   "metadata": {
    "id": "1CUmXEtPyBw6"
   },
   "source": [
    "# MGMT 467 — Prompt-Driven Lab (with Commented Examples)\n",
    "## Kaggle ➜ Google Cloud Storage ➜ BigQuery ➜ Data Quality (DQ)\n",
    "\n",
    "**How to use this notebook**\n",
    "- Each section gives you a **Build Prompt** to paste into Gemini/Vertex AI (or Gemini in Colab).\n",
    "- Below each prompt, you’ll see a **commented example** of what a good LLM answer might look like.\n",
    "- **Do not** just uncomment and run. Use the prompt to generate your own code, then compare to the example.\n",
    "- After every step, run the **Verification Prompt**, and write the **Reflection** in Markdown.\n",
    "\n",
    "> Goal today: Download the Netflix dataset (Kaggle) → Stage on GCS → Load into BigQuery → Run DQ profiling (missingness, duplicates, outliers, anomaly flags).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dQlu93cyBw7",
   "metadata": {
    "id": "3dQlu93cyBw7"
   },
   "source": [
    "### Academic integrity & LLM usage\n",
    "- Use the prompts here to generate your own code cells.\n",
    "- Read concept notes and write the reflection answers in your own words.\n",
    "- Keep credentials out of code. Upload `kaggle.json` when asked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swD34s-HyBw7",
   "metadata": {
    "id": "swD34s-HyBw7"
   },
   "source": [
    "## Learning objectives\n",
    "1) Explain **why** we stage data in GCS and load it to BigQuery.  \n",
    "2) Build an **idempotent**, auditable pipeline.  \n",
    "3) Diagnose **missingness**, **duplicates**, and **outliers** and justify cleaning choices.  \n",
    "4) Connect DQ decisions to **business/ML impact**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442aMto1yBw7",
   "metadata": {
    "id": "442aMto1yBw7"
   },
   "source": [
    "## 0) Environment setup — What & Why\n",
    "Authenticate Colab to Google Cloud so we can use `gcloud`, GCS, and BigQuery. Set **PROJECT_ID** and **REGION** once for consistency (cost/latency)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vHXKgrUQyBw8",
   "metadata": {
    "id": "vHXKgrUQyBw8"
   },
   "source": [
    "### Build Prompt (paste to LLM)\n",
    "You are my cloud TA. Generate a single **Colab code cell** that:\n",
    "1) Authenticates to Google Cloud in Colab,  \n",
    "2) Prompts for `PROJECT_ID` via `input()` and sets `REGION=\"us-central1\"` (editable),  \n",
    "3) Exports `GOOGLE_CLOUD_PROJECT`,  \n",
    "4) Runs `gcloud config set project $GOOGLE_CLOUD_PROJECT`,  \n",
    "5) Prints both values. Add 2–3 comments explaining what/why.\n",
    "End with a comment: `# Done: Auth + Project/Region set`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83_g0AEdyBw8",
   "metadata": {
    "id": "83_g0AEdyBw8"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Auth + Project/Region (commented; write your own cell using the prompt)\n",
    "# # from google.colab import auth\n",
    "# # auth.authenticate_user()\n",
    "# #\n",
    "# # import os\n",
    "# # PROJECT_ID = input(\"Enter your GCP Project ID: \").strip()\n",
    "# # REGION = \"us-central1\"  # keep consistent; change if instructed\n",
    "# # os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "# # print(\"Project:\", PROJECT_ID, \"| Region:\", REGION)\n",
    "# #\n",
    "# # # Set active project for gcloud/BigQuery CLI\n",
    "# # !gcloud config set project $GOOGLE_CLOUD_PROJECT\n",
    "# # !gcloud config get-value project\n",
    "# # # Done: Auth + Project/Region set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648c532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9648c532",
    "outputId": "cf2176c2-927a-4c2b-c033-553330c9feaa"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "import os\n",
    "PROJECT_ID = input(\"Enter your GCP Project ID: \").strip()\n",
    "REGION = \"us-central1\"  # keep consistent; change if instructed\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "print(\"Project:\", PROJECT_ID, \"| Region:\", REGION)\n",
    "\n",
    "# Set active project for gcloud/BigQuery CLI\n",
    "# This ensures subsequent gcloud/bq commands use this project.\n",
    "!gcloud config set project $GOOGLE_CLOUD_PROJECT\n",
    "!gcloud config get-value project\n",
    "# Done: Auth + Project/Region set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mX7dkJBWyBw8",
   "metadata": {
    "id": "mX7dkJBWyBw8"
   },
   "source": [
    "**Reflection:** Why do we set `PROJECT_ID` and `REGION` at the top? What can go wrong if we don’t?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c315d",
   "metadata": {
    "id": "002c315d"
   },
   "source": [
    "**Reflection:** Setting `PROJECT_ID` and `REGION` at the beginning is crucial for consistency and avoiding errors when interacting with Google Cloud services like GCS and BigQuery.\n",
    "\n",
    "If we don't set them explicitly, subsequent `gcloud`, `gsutil`, or `bq` commands might use default values or rely on the environment setup in unpredictable ways. This can lead to:\n",
    "- **Resource creation in the wrong project or region:** Incurring costs or violating compliance requirements.\n",
    "- **Difficulty finding resources:** If resources are scattered across different projects or regions.\n",
    "- **Inconsistent behavior:** Depending on where the commands are run or how the environment is configured.\n",
    "- **Errors:** Commands might fail if the project or region is not set or is incorrect.\n",
    "\n",
    "Setting them upfront ensures all operations are performed within the intended scope, making the pipeline more reliable and auditable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6pavVicOAeVS",
   "metadata": {
    "id": "6pavVicOAeVS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7r50gF8GyBw8",
   "metadata": {
    "id": "7r50gF8GyBw8"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a short cell that prints the active project using `gcloud config get-value project` and echoes the `REGION` you set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7e3bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5b7e3bc",
    "outputId": "9d5fcc54-1e44-4288-f32b-16aae331c359"
   },
   "outputs": [],
   "source": [
    "# Print the active project using gcloud config get-value project and echo the REGION\n",
    "!gcloud config get-value project\n",
    "import os\n",
    "print(\"REGION:\", os.environ.get(\"REGION\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsT-RZ7fyBw8",
   "metadata": {
    "id": "CsT-RZ7fyBw8"
   },
   "source": [
    "## 1) Kaggle API — What & Why\n",
    "Use Kaggle CLI for reproducible downloads. Store `kaggle.json` at `~/.kaggle/kaggle.json` with `0600` permissions to protect secrets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oofm7F-VyBw9",
   "metadata": {
    "id": "Oofm7F-VyBw9"
   },
   "source": [
    "### Build Prompt\n",
    "Generate a **single Colab code cell** that:\n",
    "- Prompts me to upload `kaggle.json`,\n",
    "- Saves to `~/.kaggle/kaggle.json` with `0600` permissions,\n",
    "- Prints `kaggle --version`.\n",
    "Add comments about security and reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6-ZK8HA6yBw9",
   "metadata": {
    "id": "6-ZK8HA6yBw9"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Kaggle setup (commented)\n",
    "# # from google.colab import files\n",
    "# # print(\"Upload your kaggle.json (Kaggle > Account > Create New API Token)\")\n",
    "# # uploaded = files.upload()\n",
    "# #\n",
    "# # import os\n",
    "# # os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "# # with open('/root/.kaggle/kaggle.json', 'wb') as f:\n",
    "# #     f.write(uploaded[list(uploaded.keys())[0]])\n",
    "# # os.chmod('/root/.kaggle/kaggle.json', 0o600)  # owner-only\n",
    "# #\n",
    "# # !kaggle --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a7be6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "4d4a7be6",
    "outputId": "28655e62-12fb-4d67-d5c5-94a44de67a19"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print(\"Upload your kaggle.json (Kaggle > Account > Create New API Token)\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "import os\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "with open('/root/.kaggle/kaggle.json', 'wb') as f:\n",
    "    f.write(uploaded[list(uploaded.keys())[0]])\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)  # owner-only permissions\n",
    "\n",
    "!kaggle --version\n",
    "# Done: Kaggle setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LSz6fLsLyBw9",
   "metadata": {
    "id": "LSz6fLsLyBw9"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a one-liner that runs `kaggle --help | head -n 20` to show the CLI is ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c89e7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93c89e7c",
    "outputId": "0388a6e6-88d7-4222-86c1-8d0ac2c8ede7"
   },
   "outputs": [],
   "source": [
    "!kaggle --help | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exoyP5AmyBw9",
   "metadata": {
    "id": "exoyP5AmyBw9"
   },
   "source": [
    "**Reflection:** Why require strict `0600` permissions on API tokens? What risks are we avoiding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4c35f",
   "metadata": {
    "id": "26c4c35f"
   },
   "source": [
    "**Reflection:** Requiring strict `0600` permissions on API tokens (like `kaggle.json`) is a critical security measure. The `0600` permission means that only the owner of the file has read and write access, and no other user (including users in the same group or all other users) has any access.\n",
    "\n",
    "The risks we are avoiding by setting these strict permissions include:\n",
    "- **Unauthorized access and usage:** If other users on the system (especially in a shared environment like Colab) could read your API token, they could potentially use your Kaggle account to download data, make submissions, or access any other resources linked to your account.\n",
    "- **Credential compromise:** API tokens are essentially passwords that grant access to external services. Protecting them with strict permissions prevents them from being accidentally exposed or read by malicious scripts or users.\n",
    "- **Data breaches:** Depending on the API the token is for, unauthorized access could lead to sensitive data being downloaded or exposed.\n",
    "\n",
    "By limiting access to the token file to only the owner, we significantly reduce the attack surface and protect the associated account and data from unauthorized access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8h92sNHAyBw9",
   "metadata": {
    "id": "8h92sNHAyBw9"
   },
   "source": [
    "## 2) Download & unzip dataset — What & Why\n",
    "Keep raw files under `/content/data/raw` for predictable paths and auditing.\n",
    "**Dataset:** `sayeeduddin/netflix-2025user-behavior-dataset-210k-records`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OXyfioBpyBw9",
   "metadata": {
    "id": "OXyfioBpyBw9"
   },
   "source": [
    "### Build Prompt\n",
    "Generate a **Colab code cell** that:\n",
    "- Creates `/content/data/raw`,\n",
    "- Downloads the dataset to `/content/data` with Kaggle CLI,\n",
    "- Unzips into `/content/data/raw` (overwrite OK),\n",
    "- Lists all CSVs with sizes in a neat table.\n",
    "Include comments describing each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1eb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acc1eb68",
    "outputId": "723f4296-6569-4937-cd2f-e31510e96667"
   },
   "outputs": [],
   "source": [
    "# Create directory for raw data\n",
    "!mkdir -p /content/data/raw\n",
    "\n",
    "# Download the dataset using Kaggle CLI to /content/data\n",
    "!kaggle datasets download -d sayeeduddin/netflix-2025user-behavior-dataset-210k-records -p /content/data\n",
    "\n",
    "# Unzip the downloaded dataset into the raw data directory, overwriting if necessary\n",
    "!unzip -o /content/data/*.zip -d /content/data/raw\n",
    "\n",
    "# List all CSV files in the raw data directory with their sizes in a table format\n",
    "!ls -lh /content/data/raw/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QzwzjCKnyBw9",
   "metadata": {
    "id": "QzwzjCKnyBw9"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Download & unzip (commented)\n",
    "# # !mkdir -p /content/data/raw\n",
    "# # !kaggle datasets download -d sayeeduddin/netflix-2025user-behavior-dataset-210k-records -p /content/data\n",
    "# # !unzip -o /content/data/*.zip -d /content/data/raw\n",
    "# # # List CSV inventory\n",
    "# # !ls -lh /content/data/raw/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ed7af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "709ed7af",
    "outputId": "990796bb-d4ff-4586-c25c-1e50c1c02560"
   },
   "outputs": [],
   "source": [
    "# Verify contents by listing the netflix/ prefix and showing object sizes\n",
    "!gcloud storage ls --readable-sizes gs://$BUCKET_NAME/netflix/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AdiqVeh7yBw9",
   "metadata": {
    "id": "AdiqVeh7yBw9"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a snippet that asserts there are exactly **six** CSV files and prints their names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241d4d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f241d4d7",
    "outputId": "abf63997-769d-4d2d-fe26-c04e74b86419"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "csv_files = glob.glob('/content/data/raw/*.csv')\n",
    "assert len(csv_files) == 6, f\"Expected 6 CSV files, but found {len(csv_files)}\"\n",
    "print(\"CSV files found:\", csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xZ3OBRh3yBw9",
   "metadata": {
    "id": "xZ3OBRh3yBw9"
   },
   "source": [
    "**Reflection:** Why is keeping a clean file inventory (names, sizes) useful downstream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e65a0",
   "metadata": {
    "id": "ca1e65a0"
   },
   "source": [
    "**Reflection:** Keeping a clean file inventory with names and sizes is useful downstream for several reasons:\n",
    "\n",
    "- **Auditing and reproducibility:** A clear inventory helps track exactly which files were used as input for subsequent steps (like loading into BigQuery). This is essential for auditing and ensuring that analyses or models can be reproduced with the same source data.\n",
    "- **Troubleshooting:** If there are issues downstream (e.g., missing data, unexpected file sizes), the inventory provides a quick reference to verify the initial state of the raw files.\n",
    "- **Automation and scripting:** Having a predictable and listed inventory makes it easier to automate downstream processes that need to read or process these files by name or size.\n",
    "- **Data discovery:** For others using the pipeline or dataset, an inventory provides a clear overview of the available raw data files.\n",
    "- **Detecting changes:** Comparing inventories over time can help detect unexpected changes or issues with the data source or download process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BHSwOv7LBUXx",
   "metadata": {
    "id": "BHSwOv7LBUXx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Kty2SB0oyBw-",
   "metadata": {
    "id": "Kty2SB0oyBw-"
   },
   "source": [
    "## 3) Create GCS bucket & upload — What & Why\n",
    "Stage in GCS → consistent, versionable source for BigQuery loads. Bucket names must be **globally unique**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VPtwyEcGyBw-",
   "metadata": {
    "id": "VPtwyEcGyBw-"
   },
   "source": [
    "### Build Prompt\n",
    "Generate a **Colab code cell** that:\n",
    "- Creates a unique bucket in `${REGION}` (random suffix),\n",
    "- Saves name to `BUCKET_NAME` env var,\n",
    "- Uploads all CSVs to `gs://$BUCKET_NAME/netflix/`,\n",
    "- Prints the bucket name and explains staging benefits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YORGeJYoyBw-",
   "metadata": {
    "id": "YORGeJYoyBw-"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — GCS staging (commented)\n",
    "# # import uuid, os\n",
    "# # bucket_name = f\"mgmt467-netflix-{uuid.uuid4().hex[:8]}\"\n",
    "# # os.environ[\"BUCKET_NAME\"] = bucket_name\n",
    "# # !gcloud storage buckets create gs://$BUCKET_NAME --location=$REGION\n",
    "# # !gcloud storage cp /content/data/raw/* gs://$BUCKET_NAME/netflix/\n",
    "# # print(\"Bucket:\", bucket_name)\n",
    "# # # Verify contents\n",
    "# # !gcloud storage ls gs://$BUCKET_NAME/netflix/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566787e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "566787e1",
    "outputId": "c5f2e48b-9b93-4769-cd40-ca97ab58f7ea"
   },
   "outputs": [],
   "source": [
    "import uuid, os\n",
    "bucket_name = f\"mgmt467-netflix-{uuid.uuid4().hex[:8]}\"\n",
    "os.environ[\"BUCKET_NAME\"] = bucket_name\n",
    "\n",
    "# Create the GCS bucket in the US multi-region\n",
    "!gcloud storage buckets create gs://$BUCKET_NAME --location=US\n",
    "\n",
    "# Upload all CSVs to the specified GCS path\n",
    "!gcloud storage cp /content/data/raw/* gs://$BUCKET_NAME/netflix/\n",
    "\n",
    "print(\"Bucket:\", bucket_name)\n",
    "print(\"\\nData staged in GCS for consistent, versionable source for BigQuery loads.\")\n",
    "\n",
    "# Verify contents\n",
    "!gcloud storage ls gs://$BUCKET_NAME/netflix/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Sdhns0fjyBw-",
   "metadata": {
    "id": "Sdhns0fjyBw-"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a snippet that lists the `netflix/` prefix and shows object sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17dd011",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e17dd011",
    "outputId": "f89afc71-6946-4045-8218-6fd7ab5b8c33"
   },
   "outputs": [],
   "source": [
    "# Verify contents by listing the netflix/ prefix and showing object sizes\n",
    "!gcloud storage ls --readable-sizes gs://$BUCKET_NAME/netflix/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2SVADT9yBw-",
   "metadata": {
    "id": "q2SVADT9yBw-"
   },
   "source": [
    "**Reflection:** Name two benefits of staging in GCS vs loading directly from local Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a259b",
   "metadata": {
    "id": "953a259b"
   },
   "source": [
    "**Reflection:** Two key benefits of staging data in Google Cloud Storage (GCS) versus loading directly from local Colab are:\n",
    "\n",
    "1.  **Durability and Accessibility:** Data in GCS is highly durable and accessible from various Google Cloud services (like BigQuery, Dataflow, AI Platform) and even external applications. Loading directly from Colab means the data is tied to the Colab runtime, which is ephemeral. If the runtime restarts or the notebook session ends, the local data is lost, requiring re-downloading. GCS provides persistent storage.\n",
    "2.  **Scalability and Performance for Cloud Services:** Loading data into BigQuery (or other cloud services) is significantly more scalable and often faster when the data source is in GCS. Cloud services are optimized to read data efficiently from cloud storage. Loading large datasets directly from a Colab instance's local disk can be slow and less reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jO5oYoPHyBw-",
   "metadata": {
    "id": "jO5oYoPHyBw-"
   },
   "source": [
    "## 4) BigQuery dataset & loads — What & Why\n",
    "Create dataset `netflix` and load six CSVs with **autodetect** for speed (we’ll enforce schemas later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dCTUUrjhyBw-",
   "metadata": {
    "id": "dCTUUrjhyBw-"
   },
   "source": [
    "### Build Prompt (two cells)\n",
    "**Cell A:** Create (idempotently) dataset `netflix` in US multi-region; if it exists, print a friendly message.  \n",
    "**Cell B:** Load tables from `gs://$BUCKET_NAME/netflix/`:\n",
    "`users, movies, watch_history, recommendation_logs, search_logs, reviews`\n",
    "with `--skip_leading_rows=1 --autodetect --source_format=CSV`.\n",
    "Finish with row-count queries for each table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ubme3sxVyBw-",
   "metadata": {
    "id": "Ubme3sxVyBw-"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — BigQuery dataset (commented)\n",
    "# # DATASET=\"netflix\"\n",
    "# # # Attempt to create; ignore if exists\n",
    "# # !bq --location=US mk -d --description \"MGMT467 Netflix dataset\" $DATASET || echo \"Dataset may already exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa8107",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbaa8107",
    "outputId": "a38d2edf-4d74-4f9a-8877-3e4931f23542"
   },
   "outputs": [],
   "source": [
    "DATASET=\"netflix\"\n",
    "# Attempt to create; ignore if exists\n",
    "!bq --location=US mk -d --description \"MGMT467 Netflix dataset\" $DATASET || echo \"Dataset may already exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FwQ5OdUgyBw-",
   "metadata": {
    "id": "FwQ5OdUgyBw-"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Load tables (commented)\n",
    "# # tables = {\n",
    "# #   \"users\": \"users.csv\",\n",
    "# #   \"movies\": \"movies.csv\",\n",
    "# #   \"watch_history\": \"watch_history.csv\",\n",
    "# #   \"recommendation_logs\": \"recommendation_logs.csv\",\n",
    "# #   \"search_logs\": \"search_logs.csv\",\n",
    "# #   \"reviews\": \"reviews.csv\",\n",
    "# # }\n",
    "# # import os\n",
    "# # for tbl, fname in tables.items():\n",
    "# #   src = f\"gs://{os.environ['BUCKET_NAME']}/netflix/{fname}\"\n",
    "# #   print(\"Loading\", tbl, \"from\", src)\n",
    "# #   !bq load --skip_leading_rows=1 --autodetect --source_format=CSV $DATASET.$tbl $src\n",
    "# #\n",
    "# # # Row counts\n",
    "# # for tbl in tables.keys():\n",
    "# #   !bq query --nouse_legacy_sql \"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `${GOOGLE_CLOUD_PROJECT}.netflix.{tbl}`\".format(tbl=tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cd558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b7cd558",
    "outputId": "dbc744d1-d911-4a64-c961-e0557d66e4aa"
   },
   "outputs": [],
   "source": [
    "tables = {\n",
    "  \"users\": \"users.csv\",\n",
    "  \"movies\": \"movies.csv\",\n",
    "  \"watch_history\": \"watch_history.csv\",\n",
    "  \"recommendation_logs\": \"recommendation_logs.csv\",\n",
    "  \"search_logs\": \"search_logs.csv\",\n",
    "  \"reviews\": \"reviews.csv\",\n",
    "}\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ID = os.environ['GOOGLE_CLOUD_PROJECT']\n",
    "DATASET = \"netflix\"\n",
    "\n",
    "for tbl, fname in tables.items():\n",
    "  src = f\"gs://{os.environ['BUCKET_NAME']}/netflix/{fname}\"\n",
    "  print(f\"Loading {tbl} from {src}\")\n",
    "  # Corrected bq load syntax\n",
    "  !bq load --skip_leading_rows=1 --autodetect --source_format=CSV {DATASET}.{tbl} {src}\n",
    "\n",
    "# Row counts\n",
    "print(\"\\nRow counts:\")\n",
    "for tbl in tables.keys():\n",
    "  query = f\"SELECT '{tbl}' AS table_name, COUNT(*) AS n FROM `{PROJECT_ID}.{DATASET}.{tbl}`\"\n",
    "  print(f\"Executing query for table: {tbl}\")\n",
    "  # Using subprocess to execute the bq query command\n",
    "  process = subprocess.run(['bq', 'query', '--nouse_legacy_sql', query], capture_output=True, text=True)\n",
    "  print(process.stdout)\n",
    "  if process.stderr:\n",
    "    print(f\"Error for table {tbl}:\")\n",
    "    print(process.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X1DL4ASiyBw-",
   "metadata": {
    "id": "X1DL4ASiyBw-"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a single query that returns `table_name, row_count` for all six tables in `${GOOGLE_CLOUD_PROJECT}.netflix`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27de678",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f27de678",
    "outputId": "dabab1d6-e43e-4a66-efd4-fe5487804ccb"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT 'users' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.users`\n",
    "UNION ALL\n",
    "SELECT 'movies' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.movies`\n",
    "UNION ALL\n",
    "SELECT 'watch_history' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.watch_history`\n",
    "UNION ALL\n",
    "SELECT 'recommendation_logs' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.recommendation_logs`\n",
    "UNION ALL\n",
    "SELECT 'search_logs' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.search_logs`\n",
    "UNION ALL\n",
    "SELECT 'reviews' AS table_name, COUNT(*) AS row_count FROM `{}.netflix.reviews`\n",
    "\"\"\".format(project_id, project_id, project_id, project_id, project_id, project_id)\n",
    "\n",
    "\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "for row in results:\n",
    "    print(f\"Table: {row.table_name}, Row Count: {row.row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kufpo4wnyBw-",
   "metadata": {
    "id": "kufpo4wnyBw-"
   },
   "source": [
    "**Reflection:** When is `autodetect` acceptable? When should you enforce explicit schemas and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf96186",
   "metadata": {
    "id": "bcf96186"
   },
   "source": [
    "**Reflection:** BigQuery's `autodetect` is acceptable for initial data exploration or when dealing with well-structured, consistent data sources where the schema is unlikely to change. It's quick and convenient for getting data loaded quickly.\n",
    "\n",
    "However, you should enforce explicit schemas when:\n",
    "- **Data consistency is critical:** Autodetect might infer incorrect data types, leading to data corruption or errors during queries. Explicit schemas ensure data conforms to expected types.\n",
    "- **Schema evolution needs control:** When schemas change over time, explicit schemas allow for controlled updates and prevent unexpected issues.\n",
    "- **Performance optimization is needed:** Explicitly defining schemas can sometimes lead to better query performance as BigQuery knows the data types upfront.\n",
    "- **Complex data types are involved:** Autodetect might struggle with nested or repeated fields.\n",
    "- **Data quality requires strict validation:** Explicit schemas act as a form of data validation, rejecting data that doesn't conform.\n",
    "\n",
    "Enforcing explicit schemas provides more control, predictability, and robustness for production pipelines and critical datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H0xLzERRyBw_",
   "metadata": {
    "id": "H0xLzERRyBw_"
   },
   "source": [
    "## 5) Data Quality (DQ) — Concepts we care about\n",
    "- **Missingness** (MCAR/MAR/MNAR). Impute vs drop. Add `is_missing_*` indicators.\n",
    "- **Duplicates** (exact vs near). Double-counted engagement corrupts labels & KPIs.\n",
    "- **Outliers** (IQR). Winsorize/cap vs robust models. Always **flag** and explain.\n",
    "- **Reproducibility**. Prefer `CREATE OR REPLACE` and deterministic keys.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EP9qCLJSyBw_",
   "metadata": {
    "id": "EP9qCLJSyBw_"
   },
   "source": [
    "### 5.1 Missingness (users) — What & Why\n",
    "Measure % missing and check if missingness depends on another variable (MAR) → potential bias & instability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2lnAuW88yBw_",
   "metadata": {
    "id": "2lnAuW88yBw_"
   },
   "source": [
    "### Build Prompt\n",
    "Generate **two BigQuery SQL cells**:\n",
    "1) Total rows and % missing in `region`, `plan_tier`, `age_band` from `users`.\n",
    "2) `% plan_tier missing by region` ordered descending. Add comments on MAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BX11eQYiyBw_",
   "metadata": {
    "id": "BX11eQYiyBw_"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Missingness profile (commented)\n",
    "# # -- Users: % missing per column\n",
    "# # WITH base AS (\n",
    "# #   SELECT COUNT(*) n,\n",
    "# #          COUNTIF(region IS NULL) miss_region,\n",
    "# #          COUNTIF(plan_tier IS NULL) miss_plan,\n",
    "# #          COUNTIF(age_band IS NULL) miss_age\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`\n",
    "# # )\n",
    "# # SELECT n,\n",
    "# #        ROUND(100*miss_region/n,2) AS pct_missing_region,\n",
    "# #        ROUND(100*miss_plan/n,2)   AS pct_missing_plan_tier,\n",
    "# #        ROUND(100*miss_age/n,2)    AS pct_missing_age_band\n",
    "# # FROM base;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d65564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36d65564",
    "outputId": "208a3384-574f-4f87-bd02-c02c23f2e736"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "# Get and print schema of the users table\n",
    "table_ref = client.dataset(\"netflix\").table(\"users\")\n",
    "table = client.get_table(table_ref)\n",
    "print(\"Schema of the users table:\")\n",
    "for field in table.schema:\n",
    "    print(f\"- {field.name}: {field.field_type}\")\n",
    "\n",
    "# Users: % missing per column\n",
    "query = \"\"\"\n",
    "WITH base AS (\n",
    "  SELECT COUNT(*) n,\n",
    "         COUNTIF(country IS NULL) miss_country,\n",
    "         COUNTIF(subscription_plan IS NULL) miss_plan,\n",
    "         COUNTIF(age IS NULL) miss_age\n",
    "  FROM `{}.netflix.users`\n",
    ")\n",
    "SELECT n,\n",
    "       ROUND(100*miss_country/n,2) AS pct_missing_country,\n",
    "       ROUND(100*miss_plan/n,2)   AS pct_missing_subscription_plan,\n",
    "       ROUND(100*miss_age/n,2)    AS pct_missing_age\n",
    "FROM base\n",
    "\"\"\".format(project_id)\n",
    "\n",
    "print(\"\\nExecuting missingness query:\")\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "for row in results:\n",
    "    print(f\"N: {row.n}, Pct Missing Country: {row.pct_missing_country}, Pct Missing Subscription Plan: {row.pct_missing_subscription_plan}, Pct Missing Age: {row.pct_missing_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lIP7UbzgyBw_",
   "metadata": {
    "id": "lIP7UbzgyBw_"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — MAR by region (commented)\n",
    "# # SELECT region,\n",
    "# #        COUNT(*) AS n,\n",
    "# #        ROUND(100*COUNTIF(plan_tier IS NULL)/COUNT(*),2) AS pct_missing_plan_tier\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`\n",
    "# # GROUP BY region\n",
    "# # ORDER BY pct_missing_plan_tier DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77d623",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "816d30f3e0c04db8a69794094705289b",
      "29592119d2414c04951cba190bc45d56",
      "abeee4c0be1c49ae913bf2f14a9541e2",
      "af6ca09d45bc4b2e94a3c53ff09d1cb9",
      "711fc74b56ed4055b238c4b1b15975ef",
      "d0d5a3ec44e64cac817b9d64c326731d",
      "8d525701448d4939b87602c7dc8a5206",
      "887c1989a9a440dbbc270bb857461e8f",
      "728adecfd18946ca99a6a7727037d73e",
      "d6460c8423294d9b8b445ac87d5ff7c9",
      "a9a732212f284930b459f44b393760a2",
      "aa6cbe23a988490eaebf9cf1f6c71590",
      "48562e37be004022aa5d225aa54c98ec",
      "36a8e0b6e12c48d88c39d844e24354f3",
      "144d62ad8f004c82b7b77b9d80268675",
      "2dd2d8925ae24095a35b82c84bafa798",
      "61a2441fbe9c421abc2926695af925c4",
      "15aef2a05618401fa316603a627dbdf6",
      "4538fcbc67f046d7aa7941f6c6f5ae19",
      "5b7f4e0e6dda4e5482c62fe0aed850f3",
      "8b39cbfb8bde476593b784bc1fa03a94",
      "b738748999ff44c4bdb5235a39c052ce"
     ]
    },
    "id": "9b77d623",
    "outputId": "fc661808-b617-4aca-d013-847e6fed160b"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Verification query: print missingness percentages\n",
    "WITH base AS (\n",
    "  SELECT COUNT(*) n,\n",
    "         COUNTIF(country IS NULL) miss_country,\n",
    "         COUNTIF(subscription_plan IS NULL) miss_plan,\n",
    "         COUNTIF(age IS NULL) miss_age\n",
    "  FROM `netflix.users`\n",
    ")\n",
    "SELECT ROUND(100*miss_country/n,2) AS pct_missing_country,\n",
    "       ROUND(100*miss_plan/n,2)   AS pct_missing_subscription_plan,\n",
    "       ROUND(100*miss_age/n,2)    AS pct_missing_age\n",
    "FROM base;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08247f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "3bd2290d82414b7485e75a5c34c64b2f",
      "99c9fcb3a893460fa1e7f738c34cc990",
      "7096edd59285480bace5f743021b64c2",
      "15c54fcc588f40fdab2023eb70766cdc",
      "ea8a318618754bf68f0fbcb1145dcfed",
      "e3894ad6b8774e15ba3908333841e232",
      "6542a90427d7423b976481e405630090",
      "67323c7023d14f17bbb75a55cb70a92e",
      "b009cd832ad8487cad9703e91deb094e",
      "4ac02fa6880a40948271c1fbf1936b9f",
      "92d66e7a10d6460a96062c3fb2d63dfa",
      "18dd9a86da854fa98de79821a317d6a5",
      "329b7a0c1b694ec5b9a6005328137367",
      "c60a7cd6d9bc45babae47a47120cfaee",
      "a049cf8373d246f79e141788fcdbb1a2",
      "80b2f5b06e1c43afa14217642ef8916e",
      "c2c23da4bd354bf38b6c70eebe8bbaff",
      "08752b832ee74ce68a56bef6216d5b2c",
      "81c6c7cc4845469d9cfaa4c7572f7f5f",
      "9c4cfb4056f64173b2c6de1f5188f579",
      "3ba5e552598445a3b99c5a00b90cabaa",
      "18981b18ebb44c0d80445f9c2e301ce6"
     ]
    },
    "id": "3d08247f",
    "outputId": "2e0c323e-2055-415e-d019-888a641187db"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT country,\n",
    "       COUNT(*) AS n,\n",
    "       ROUND(100*COUNTIF(subscription_plan IS NULL)/COUNT(*),2) AS pct_missing_subscription_plan\n",
    "FROM `netflix.users`\n",
    "GROUP BY country\n",
    "ORDER BY pct_missing_subscription_plan DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lmf9CFyJyBw_",
   "metadata": {
    "id": "Lmf9CFyJyBw_"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a query that prints the three missingness percentages from (1), rounded to two decimals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mv0CPdVW7RMB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "527efff8dcac4b92900763e52e7976dd",
      "298e8008be4f4de3b7bcbf02507396b7",
      "dcb996a9261a479885e4d515ccbcb29a",
      "f869751d649d4f0aa94ff0d57d242f71",
      "1e558d9155f54bfeb8a577453bbf9665",
      "b93ff21ca9b745d5ba8d6376c0e7c194",
      "60dbbd825da24e4589b48101108f4c58",
      "9584e02795b6461fb13c99f810713333",
      "2c3ff9c38f7a42339ed5b9f8fcf6b7d9",
      "c25903be1a8c4a19871151a5005f1134",
      "5a6331cd0ee148309e6471c805dadc73",
      "1617e766dd044c4cbd831108ba27483d",
      "16acbe38d7b047b58361055456ea7897",
      "93923b821cf049f08d79858d37e5c38d",
      "fde82f60a2904d9980cf9f25cf2cf9ac",
      "d237fed3bb464af8977d0a51be0811b7",
      "81ce06a576874d66a378ed13aa25926b",
      "92a15b72c90b4be7939c4c2b5ff54eae",
      "e8f97208848848769e223a3ee7531530",
      "5f8357763fd94c7dbb9141f9991e9a5a",
      "c372b301020f4f4595054ce002c90e68",
      "b50badb86c1b4467879a87ef1bb80741"
     ]
    },
    "id": "mv0CPdVW7RMB",
    "outputId": "78e34f51-0bbf-4d12-b1ee-5d5eb522e2e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%bigquery\n",
    "-- Verification query: print missingness percentages\n",
    "WITH base AS (\n",
    "  SELECT COUNT(*) n,\n",
    "         COUNTIF(country IS NULL) miss_country,\n",
    "         COUNTIF(subscription_plan IS NULL) miss_plan,\n",
    "         COUNTIF(age IS NULL) miss_age\n",
    "  FROM `netflix.users`\n",
    ")\n",
    "SELECT ROUND(100*miss_country/n,2) AS pct_missing_country,\n",
    "       ROUND(100*miss_plan/n,2)   AS pct_missing_subscription_plan,\n",
    "       ROUND(100*miss_age/n,2)    AS pct_missing_age\n",
    "FROM base;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G0EEa3OgyBw_",
   "metadata": {
    "id": "G0EEa3OgyBw_"
   },
   "source": [
    "**Reflection:** Which columns are most missing? Hypothesize MCAR/MAR/MNAR and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e10c0",
   "metadata": {
    "id": "c31e10c0"
   },
   "source": [
    "**Reflection:** Based on the missingness analysis, the `age` column is the most missing with 11.93% of values missing. The `country` and `subscription_plan` columns have no missing values (0.0%).\n",
    "\n",
    "Hypotheses about the missing data mechanisms:\n",
    "- **Age:** The missingness in the `age` column could be **Missing At Random (MAR)** or **Missing Not At Random (MNAR)**. It might be MAR if the probability of age being missing depends on another observed variable, such as country or device type (e.g., users from certain regions or on certain devices are less likely to provide age). It could be MNAR if the probability of age being missing depends on the age itself (e.g., very young or very old users are less likely to provide their age). It's less likely to be **Missing Completely At Random (MCAR)**, where missingness is unrelated to any variable, observed or unobserved, given the specific nature of age data.\n",
    "\n",
    "To determine the actual mechanism, further analysis would be needed to see if missingness in 'age' is correlated with other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CZJKdg2NyBw_",
   "metadata": {
    "id": "CZJKdg2NyBw_"
   },
   "source": [
    "### 5.2 Duplicates (watch_history) — What & Why\n",
    "Find exact duplicate interaction records and keep **one best** per group (deterministic policy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Du-YTVLPyBw_",
   "metadata": {
    "id": "Du-YTVLPyBw_"
   },
   "source": [
    "### Build Prompt\n",
    "Generate **two BigQuery SQL cells**:\n",
    "1) Report duplicate groups on `(user_id, movie_id, event_ts, device_type)` with counts (top 20).\n",
    "2) Create table `watch_history_dedup` that keeps one row per group (prefer higher `progress_ratio`, then `minutes_watched`). Add comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uS5tBH2ryBw_",
   "metadata": {
    "id": "uS5tBH2ryBw_"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Detect duplicate groups (commented)\n",
    "# # SELECT user_id, movie_id, event_ts, device_type, COUNT(*) AS dup_count\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history`\n",
    "# # GROUP BY user_id, movie_id, event_ts, device_type\n",
    "# # HAVING dup_count > 1\n",
    "# # ORDER BY dup_count DESC\n",
    "# # LIMIT 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a4e6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740,
     "referenced_widgets": [
      "0cadbd83d8b54ed7a3c6c21db14cad53",
      "ba1c358cdc834473b68f9f7253f4093f",
      "43b35b26e2b643adb1feeb0240bc4fe3",
      "ffd498eb5d414fed98901542a6e2eae1",
      "4b9b426166c24a03bd53e60bb2008588",
      "d43a6471b8504bb29e88a80582c182c6",
      "361b374185c64189b72b213367ecec42",
      "9363c5328eb3483c89012a300f465a73",
      "0c37a956211a4b1cae68b604497d8d24",
      "d3eff635075942f4a22ec865cf06c8d1",
      "f08b73c4c1724537bd6d306d2f3437f3",
      "127759e52b944a2292167a8c6a09ea59",
      "b797b550552d48deb1b46d0aa9188a89",
      "9197fec7ad7443f5897c944c4c015ee3",
      "9a876f7d36bd44178e18a9a1ca9ceeb0",
      "59e23b1bab094e98a798e45a86baca75",
      "1f2305baeef64958b2b6d55129e0a8c8",
      "7e3cef5fed1047c6b93bb0206ff31fdc",
      "f6c976f2c34049d3aaa72a67fe834ada",
      "ddae827853824cb69237a20849a6e15a",
      "b8abef7322e54a6895a21905bd425baf",
      "6920c9c7a1d54cc68eb6de5310af7d95"
     ]
    },
    "id": "1b5a4e6e",
    "outputId": "1dc0eebc-83b1-4613-8d8b-61521692fe94"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "SELECT user_id,\n",
    "       movie_id,\n",
    "       watch_date,\n",
    "       device_type,\n",
    "       COUNT(*) AS duplicate_count\n",
    "FROM `netflix.watch_history`\n",
    "GROUP BY user_id, movie_id, watch_date, device_type\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY duplicate_count DESC\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KovPNGtoyBxD",
   "metadata": {
    "id": "KovPNGtoyBxD"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Keep-one policy (commented)\n",
    "# # CREATE OR REPLACE TABLE `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` AS\n",
    "# # SELECT * EXCEPT(rk) FROM (\n",
    "# #   SELECT h.*,\n",
    "# #          ROW_NUMBER() OVER (\n",
    "# #            PARTITION BY user_id, movie_id, event_ts, device_type\n",
    "# #            ORDER BY progress_ratio DESC, minutes_watched DESC\n",
    "# #          ) AS rk\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history` h\n",
    "# # )\n",
    "# # WHERE rk = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a742f00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "a1acd956d8f14fc19519306ea439258a",
      "f332b08d50ec424eb3a1c372e0517890",
      "0e7547581e3f45638d85d31a681ec393",
      "bc243d6d84b44af0a173e2530e9cc803",
      "bb306e16ba794e17b38d33acbcfa8463",
      "72442ac0b2684c80bc0b9a09a6d8a0d5",
      "6c65524361c94c429eef0b9eba320c91",
      "8b190f13925b48288f904903689be1fb",
      "e5edb5d607d74921a3ca458d8133d083",
      "c6496293ae5d4acba5d1ade52e054d2d",
      "a720f1ec2be744d2bd002e103eb472bf"
     ]
    },
    "id": "6a742f00",
    "outputId": "d09e02e1-8293-4a3b-86e4-0a23422a8691"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Create watch_history_dedup table by keeping one row per duplicate group\n",
    "CREATE OR REPLACE TABLE `netflix.watch_history_dedup` AS\n",
    "SELECT * EXCEPT(rk) FROM (\n",
    "  SELECT h.*,\n",
    "         ROW_NUMBER() OVER (\n",
    "           PARTITION BY user_id, movie_id, watch_date, device_type\n",
    "           ORDER BY progress_percentage DESC, watch_duration_minutes DESC\n",
    "         ) AS rk\n",
    "  FROM `netflix.watch_history` h\n",
    ")\n",
    "WHERE rk = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPodhsfayBxD",
   "metadata": {
    "id": "zPodhsfayBxD"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a before/after count query comparing raw vs `watch_history_dedup`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a7245",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "95d006958576402b84cb014aeeb671a3",
      "ccb5e261a0f24389bb9430f65cea25ad",
      "d539a02d59934966884d41205d42cd2d",
      "93ddcf67f0454e17bb975108c2b33ba0",
      "afba8f6485d44fd6a1c401bdd52b3399",
      "d07ac316837340a981c9fa30568d6434",
      "cf937987bb4c4e708ce700d650649b41",
      "938e21db2d0845d68677896c343fb1d2",
      "005984286de24749b214f3356c18e01c",
      "7087b10fa24f4cb1806819a26c58906c",
      "27c98df1a0bf4d6c9d7fcab18ddfd5aa",
      "1e2ed87b5a8e441581cc26da5556d833",
      "017efbf2d71a4c229fdd079b136ff1c6",
      "46569bcea51f471c85fb4fccf9691233",
      "734130359f2041d8b7e16065796190ad",
      "39f480fff13c4dcc9e8d7925ed24e3d2",
      "7042ebf93938417aaa974cb151cd00d1",
      "52ada41c967144f3a1424b18c74cc07c",
      "cb57eb0c0d88475e89c0c554498d1a82",
      "84924ff75560442da3c592fe75357de8",
      "25fcab8ed5f64cf088fae6fb4d840334",
      "c0771897b83f472d942f9aa46377730a"
     ]
    },
    "id": "253a7245",
    "outputId": "e687aab1-45d7-492e-8e2a-251d44f6af7e"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Verification: Compare row counts before and after deduplication\n",
    "SELECT\n",
    "  'raw_watch_history' AS table_name,\n",
    "  COUNT(*) AS row_count\n",
    "FROM `netflix.watch_history`\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'watch_history_dedup' AS table_name,\n",
    "  COUNT(*) AS row_count\n",
    "FROM `netflix.watch_history_dedup`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smbxLZwXyBxE",
   "metadata": {
    "id": "smbxLZwXyBxE"
   },
   "source": [
    "**Reflection:** Why do duplicates arise (natural vs system-generated)? How do they corrupt labels and KPIs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4116e",
   "metadata": {
    "id": "d9c4116e"
   },
   "source": [
    "**Reflection:** Duplicates in data can arise from several sources, broadly categorized as natural or system-generated:\n",
    "\n",
    "- **Natural Duplicates:** These are genuine occurrences that might appear as duplicates in a dataset but represent distinct events. For example, a user might genuinely watch the same movie multiple times. However, in the context of logging, multiple identical log entries for a single watch session might be system-generated if not handled properly.\n",
    "- **System-Generated Duplicates:** These are artifacts of data collection, processing, or storage systems. Examples include:\n",
    "    - **Retry mechanisms:** If a system fails to confirm a successful data write, it might retry, leading to duplicate entries.\n",
    "    - **Parallel processing:** Data processed in parallel might be written multiple times if not coordinated correctly.\n",
    "    - **Sensor/Event firing:** A single event might trigger multiple identical sensor readings or log entries due to system glitches or configuration issues.\n",
    "    - **Joins or transformations:** Incorrect joins or data transformations can sometimes create duplicate rows.\n",
    "\n",
    "Duplicates can significantly corrupt labels and KPIs:\n",
    "\n",
    "- **Corrupted Labels:** If you're building a model where the label is derived from interaction counts (e.g., \"number of movies watched\"), duplicates will inflate these counts, leading to incorrect labels and a biased model. For example, a user who watched a movie once might appear to have watched it multiple times due to duplicate logs.\n",
    "- **Corrupted KPIs:** Business metrics (KPIs) like \"total watch hours\", \"average session duration\", \"number of active users\", or \"recommendation click-through rate\" will be inaccurate if based on data with duplicates. This can lead to flawed business decisions based on inflated or skewed numbers. For instance, duplicate watch history entries will inflate total watch hours, giving a false impression of user engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efMWQDjyBxE",
   "metadata": {
    "id": "2efMWQDjyBxE"
   },
   "source": [
    "### 5.3 Outliers (minutes_watched) — What & Why\n",
    "Estimate extreme values via IQR; report % outliers; **winsorize** to P01/P99 for robustness while also **flagging** extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tikVRObryBxE",
   "metadata": {
    "id": "tikVRObryBxE"
   },
   "source": [
    "### Build Prompt\n",
    "Generate **two BigQuery SQL cells**:\n",
    "1) Compute IQR bounds for `minutes_watched` on `watch_history_dedup` and report % outliers.\n",
    "2) Create `watch_history_robust` with `minutes_watched_capped` capped at P01/P99; return quantile summaries before/after.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6wZyDSjzyBxE",
   "metadata": {
    "id": "6wZyDSjzyBxE"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — IQR outlier rate (commented)\n",
    "# # WITH dist AS (\n",
    "# #   SELECT\n",
    "# #     APPROX_QUANTILES(minutes_watched, 4)[OFFSET(1)] AS q1,\n",
    "# #     APPROX_QUANTILES(minutes_watched, 4)[OFFSET(3)] AS q3\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
    "# # ),\n",
    "# # bounds AS (\n",
    "# #   SELECT q1, q3, (q3-q1) AS iqr,\n",
    "# #          q1 - 1.5*(q3-q1) AS lo,\n",
    "\n",
    "# #          q3 + 1.5*(q3-q1) AS hi\n",
    "# #   FROM dist\n",
    "# # )\n",
    "# # SELECT\n",
    "# #   COUNTIF(h.minutes_watched < b.lo OR h.minutes_watched > b.hi) AS outliers,\n",
    "# #   COUNT(*) AS total,\n",
    "# #   ROUND(100*COUNTIF(h.minutes_watched < b.lo OR h.minutes_watched > b.hi)/COUNT(*),2) AS pct_outliers\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` h\n",
    "# # CROSS JOIN bounds b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f288a5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "b1b4b19bbe4343fa98b21278086b393d",
      "058c6518a24d44799948a68184137a6a",
      "5727335d29ae459da2dc108ba4f08c45",
      "71036211f80447578cdfde52b158b40c",
      "f547cea4f75d453fbbe61552d67da021",
      "187fc0118195476c877e23ca17b9a2dc",
      "c2e769e1ddd742978f5785ef047e4b92",
      "6b2db97fe15d45da814e7165fe1f6f29",
      "c005b5d748794c5e9f1095b81df49f25",
      "866bcc5aa12c44868e1c65bf175758ad",
      "9f606bc94e2a427084aae5e31ec38ca7",
      "227bcafb205640c6944dad5fb1e9cd72",
      "fb88c70c6d504ca4b923684076b70c46",
      "2f2a36a5d9754599b31889ea2e0899bf",
      "215572d3380a4467b972a7e25ef151e8",
      "a70444cf6e7e40c9b3695ff6ee7dcbec",
      "02fb84c50d8c4be190bc7b97a2eacc0d",
      "90c52ea7b7824971baa52b60a0d0f840",
      "e77506c76dfc461ca422a1fbd82df75a",
      "2aae774c25a44e14a2879881d859d078",
      "b122e4c424e84c30943e4ae9fd9cc5fb",
      "15a887c48507417b828e0912fa1e62f1"
     ]
    },
    "id": "4f288a5e",
    "outputId": "53043fdd-7387-4b71-e422-72651bf31462"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Watch history dedup: IQR outlier rate for watch_duration_minutes\n",
    "WITH dist AS (\n",
    "  SELECT\n",
    "    APPROX_QUANTILES(watch_duration_minutes, 4)[OFFSET(1)] AS q1,\n",
    "    APPROX_QUANTILES(watch_duration_minutes, 4)[OFFSET(3)] AS q3\n",
    "  FROM `netflix.watch_history_dedup`\n",
    "),\n",
    "bounds AS (\n",
    "  SELECT q1, q3, (q3-q1) AS iqr,\n",
    "         q1 - 1.5*(q3-q1) AS lo,\n",
    "         q3 + 1.5*(q3-q1) AS hi\n",
    "  FROM dist\n",
    ")\n",
    "SELECT\n",
    "  COUNTIF(h.watch_duration_minutes < b.lo OR h.watch_duration_minutes > b.hi) AS outliers,\n",
    "  COUNT(*) AS total,\n",
    "  ROUND(100*COUNTIF(h.watch_duration_minutes < b.lo OR h.watch_duration_minutes > b.hi)/COUNT(*),2) AS pct_outliers\n",
    "FROM `netflix.watch_history_dedup` h\n",
    "CROSS JOIN bounds b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a40cdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "aa2499c5a8e249d99cef4e58d830cea6",
      "456850e745b247349ad77b3446133ca8",
      "17f01101037b450a936c58c0085bfcae",
      "513d5321c911430c892d3a214584d351",
      "249700c057e74cf59f48e8a2548a6068",
      "eb21e387ad3b418b9af053a75a7bde15",
      "1873045ce1fe4032878f6634145168f7",
      "86a1fc0ea5dd477daf7a66b5526610c4",
      "bb362bab7f8446da907dc1121b83bdf9",
      "7ef0a98e8608416dbb544f5bb7dc3f35",
      "0fdd5bf0c3d542dabc2823c4d908288d",
      "5fa86dde73ce4ce3bd51f20b2ade277b",
      "70d7dc2010b2496c968fe01e99e6923d",
      "b899a32e9bc34666bb32862deca0aa1f",
      "0992b42a2d1d41f5b9f92e25e0dd3e3b",
      "ab21b4d8334a4f46a82c508d613f9666",
      "f20211b7e0034a48b162e2696add8e3b",
      "800710d29e78449399c0ae2f64aaf90e",
      "b1fc40d3732345898852b33af54c3b0d",
      "4c44d615863c459ab95fe03c72416675",
      "13199a8375b443ca8c1af581210c6055",
      "a082f3f26e384347953052575b3d66ab"
     ]
    },
    "id": "b1a40cdc",
    "outputId": "afb3485b-ab95-469c-b472-60f41611e60f"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Quantiles before vs after capping\n",
    "WITH before AS (\n",
    "  SELECT 'before' AS which, APPROX_QUANTILES(watch_duration_minutes, 5) AS q\n",
    "  FROM `netflix.watch_history_dedup`\n",
    "),\n",
    "after AS (\n",
    "  SELECT 'after' AS which, APPROX_QUANTILES(watch_duration_minutes_capped, 5) AS q\n",
    "  FROM `netflix.watch_history_robust`\n",
    ")\n",
    "SELECT * FROM before UNION ALL SELECT * FROM after;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d9f8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "27a6ade3029a484fb5aa6326c6c9bffd",
      "1525334ea1fd47219794d7485f9aeba7",
      "523fc5caeb2f4bfe923b9d8735809230",
      "d49dc0b8ac3941c3821ccb8b2a61c5d8",
      "e3ccb2d4e9454b4ca251083145ed6f80",
      "110296be4107498082124070f6148b85",
      "881ddfa5b6094e63b3ccd42d4d5ca43c",
      "a047dea3083d44e29e8832ed9e365841",
      "b8cbe18780314e4fb0d64907a5cc2fa3",
      "6f72a9565cae4e80af2ee20d53cc4c22",
      "18dbc69f26564a2282fdee0cf8f34fa1"
     ]
    },
    "id": "255d9f8b",
    "outputId": "9eba6a73-5cc9-46cf-fab7-a5b2a7613f83"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Create watch_history_robust with watch_duration_minutes capped at P01/P99\n",
    "CREATE OR REPLACE TABLE `netflix.watch_history_robust` AS\n",
    "WITH q AS (\n",
    "  SELECT\n",
    "    APPROX_QUANTILES(watch_duration_minutes, 100)[OFFSET(1)]  AS p01,\n",
    "    APPROX_QUANTILES(watch_duration_minutes, 100)[OFFSET(98)] AS p99\n",
    "  FROM `netflix.watch_history_dedup`\n",
    ")\n",
    "SELECT\n",
    "  h.*,\n",
    "  GREATEST(q.p01, LEAST(q.p99, h.watch_duration_minutes)) AS watch_duration_minutes_capped\n",
    "FROM `netflix.watch_history_dedup` h, q;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Za5bpcJMyBxE",
   "metadata": {
    "id": "Za5bpcJMyBxE"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — Winsorize + quantiles (commented)\n",
    "# # CREATE OR REPLACE TABLE `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust` AS\n",
    "# # WITH q AS (\n",
    "# #   SELECT\n",
    "# #     APPROX_QUANTILES(minutes_watched, 100)[OFFSET(1)]  AS p01,\n",
    "# #     APPROX_QUANTILES(minutes_watched, 100)[OFFSET(98)] AS p99\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
    "# # )\n",
    "# # SELECT\n",
    "# #   h.*,\n",
    "# #   GREATEST(q.p01, LEAST(q.p99, h.minutes_watched)) AS minutes_watched_capped\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup` h, q;\n",
    "# #\n",
    "# # -- Quantiles before vs after\n",
    "# # WITH before AS (\n",
    "# #   SELECT 'before' AS which, APPROX_QUANTILES(minutes_watched, 5) AS q\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_dedup`\n",
    "# # ),\n",
    "# # after AS (\n",
    "# #   SELECT 'after' AS which, APPROX_QUANTILES(minutes_watched_capped, 5) AS q\n",
    "# #   FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust`\n",
    "# # )\n",
    "# # SELECT * FROM before UNION ALL SELECT * FROM after;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ue6DphOSyBxE",
   "metadata": {
    "id": "ue6DphOSyBxE"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a query that shows min/median/max before vs after capping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-fPdfZps-q6K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "3984d21e8694463886ae79f4c41053b2",
      "d2f5f01275934e4faf59aee62af27abd",
      "ce98e8f7f0ce42c18ae95e5e97b93a1e",
      "42a5833823364680819f686645524e02",
      "afbfc550fdf04cf595d3ca041a7d9b32",
      "6ca87d889d654c7d81cea5eee0830797",
      "0c59c5560e9447c68ef8006f59c9fb24",
      "33ec7de5c37e4d05ba5ecb12eb4dab07",
      "0c7528dce94f442785b8ffbfcef9432d",
      "7f7e8f0d6d384fc9857d571b6529a2c9",
      "84c05cf03ed94859ba8ae965e65bf286",
      "59271b41ea1b489787ee51582d348e77",
      "8d5b6728a8f54b1dbac5a5e9e9382cee",
      "e939e58ac31d4f80a5d70d06cbbfe624",
      "4a89a2db443a462f8f828b3b509acd28",
      "467514cf04d04d7ea80b055c7b8c42fe",
      "75fab4890595486f8ad1ecc4dfbe1486",
      "4b54fe72d3e4482aa69821eea41d366b",
      "df1161b76ac04fe0b901262fcfdcaeb8",
      "71f4000f845c4472bee199725764d6b1",
      "61c1bec058924edd9aa37d90b04f12e2",
      "31da174a684d48ab8ee4affc9af7aeae"
     ]
    },
    "id": "-fPdfZps-q6K",
    "outputId": "d8734935-0589-4892-f259-95a7ced72319"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Verification: Min/Median/Max before vs after capping\n",
    "WITH before AS (\n",
    "  SELECT\n",
    "    'before' AS which,\n",
    "    MIN(watch_duration_minutes) AS min_duration,\n",
    "    APPROX_QUANTILES(watch_duration_minutes, 2)[OFFSET(1)] AS median_duration, -- Median is the 50th percentile (OFFSET(1) for 2 quantiles)\n",
    "    MAX(watch_duration_minutes) AS max_duration\n",
    "  FROM `netflix.watch_history_dedup`\n",
    "),\n",
    "after AS (\n",
    "  SELECT\n",
    "    'after' AS which,\n",
    "    MIN(watch_duration_minutes_capped) AS min_duration,\n",
    "    APPROX_QUANTILES(watch_duration_minutes_capped, 2)[OFFSET(1)] AS median_duration, -- Median is the 50th percentile\n",
    "    MAX(watch_duration_minutes_capped) AS max_duration\n",
    "  FROM `netflix.watch_history_robust`\n",
    ")\n",
    "SELECT * FROM before UNION ALL SELECT * FROM after;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6DEE-O9eyBxE",
   "metadata": {
    "id": "6DEE-O9eyBxE"
   },
   "source": [
    "**Reflection:** When might capping be harmful? Name a model type less sensitive to outliers and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c58b0e",
   "metadata": {
    "id": "93c58b0e"
   },
   "source": [
    "**Reflection:** Capping (or winsorizing) outliers can sometimes be harmful if the extreme values are genuine and contain important information. For example, in a fraud detection dataset, extreme transaction amounts might be true outliers but are critical indicators of fraudulent activity. Capping these values would obscure the very signal you're trying to detect. It can also distort the underlying distribution of the data, which might negatively impact models that assume a certain distribution.\n",
    "\n",
    "Model types less sensitive to outliers often include **tree-based models** like Decision Trees, Random Forests, and Gradient Boosting Machines (e.g., LightGBM, XGBoost). These models make decisions based on splitting data at certain thresholds. Outliers typically only affect which side of a split a data point falls on, and their extreme values don't disproportionately influence the split point itself as much as they would in models that calculate distances or averages (like linear regression or k-means clustering). The decision boundaries are determined by the majority of the data points, making them more robust to individual extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFsAWCGOyBxE",
   "metadata": {
    "id": "oFsAWCGOyBxE"
   },
   "source": [
    "### 5.4 Business anomaly flags — What & Why\n",
    "Human-readable flags help both product decisioning and ML features (e.g., binge behavior)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CO7Vm4yYyBxE",
   "metadata": {
    "id": "CO7Vm4yYyBxE"
   },
   "source": [
    "### Build Prompt\n",
    "Generate **three BigQuery SQL cells** (adjust if columns differ):\n",
    "1) In `watch_history_robust`, compute and summarize `flag_binge` for sessions > 8 hours.\n",
    "2) In `users`, compute and summarize `flag_age_extreme` if age can be parsed from `age_band` (<10 or >100).\n",
    "3) In `movies`, compute and summarize `flag_duration_anomaly` where `duration_min` < 15 or > 480 (if exists).\n",
    "Each cell should output count and percentage and include 1–2 comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rTXTOwvOyBxF",
   "metadata": {
    "id": "rTXTOwvOyBxF"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — flag_binge (commented)\n",
    "# # SELECT\n",
    "# #   COUNTIF(minutes_watched > 8*60) AS sessions_over_8h,\n",
    "# #   COUNT(*) AS total,\n",
    "# #   ROUND(100*COUNTIF(minutes_watched > 8*60)/COUNT(*),2) AS pct\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.watch_history_robust`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88e45d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "a9bafe6c25074c71baeff34aa8bec40c",
      "e40195a1258c40d4a9de282006c21ddf",
      "e61e7ae33d8a41db94162223a140803f",
      "f53f8e8792eb491aa52cd0ea0b90e84b",
      "45a5e63f8c5b49d58ab44ac353c8f3bc",
      "619340d3347249e9aae40c15fd291594",
      "501738c7ca2b4e1bb9f157ae71325357",
      "ca22986d6906491f9c19a56cb58813d5",
      "232533e8ae7b4751bade5cc3cea1446c",
      "8cf3d33f42774912a5a34c4186aff933",
      "42513f86636f458ea3572edf0bfc5bad",
      "53fe08fb3f0e406eac0eb8de062700bf",
      "3707dd07915d48ec976eeabd0b3cec9c",
      "aa3eed409171411da1de63188e95b558",
      "72c4d67a89ea445f85bef40d02f54a58",
      "376d8dfb82f04137bee8f37edbb182a6",
      "10e0fda531914d4f82d8d785c100d7bf",
      "0faf5e2907b949eeae1f551319103a77",
      "89271a11c0924d19b0e26a99a9ac9bd9",
      "740fbc923d1a4890bfedbd757429cc39",
      "80ea2d9c40d94f2cac437471931ce360",
      "d4d329ed647c4aaf9788883667fe02f1"
     ]
    },
    "id": "9d88e45d",
    "outputId": "50af40e3-6e70-4de1-e71b-39296cb767d4"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Compute and summarize flag_binge for sessions > 8 hours\n",
    "SELECT\n",
    "  COUNTIF(watch_duration_minutes_capped > 8*60) AS sessions_over_8h,\n",
    "  COUNT(*) AS total,\n",
    "  ROUND(100*COUNTIF(watch_duration_minutes_capped > 8*60)/COUNT(*),2) AS pct_sessions_over_8h\n",
    "FROM `netflix.watch_history_robust`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y95OEV3CyBxF",
   "metadata": {
    "id": "Y95OEV3CyBxF"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — flag_age_extreme (commented)\n",
    "# # SELECT\n",
    "# #   COUNTIF(CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) < 10 OR\n",
    "# #           CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) > 100) AS extreme_age_rows,\n",
    "# #   COUNT(*) AS total,\n",
    "# #   ROUND(100*COUNTIF(CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) < 10 OR\n",
    "# #                     CAST(REGEXP_EXTRACT(age_band, r'\\d+') AS INT64) > 100)/COUNT(*),2) AS pct\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.users`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35bf73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "fb57cc5104964c419b0164361e7fcb36",
      "6f7c3efdc0ed407ea38ecd72b9776846",
      "a98d93897b5a4bed9f441f87596bdcaf",
      "2ade3932899a4c0b8cda6359c698d80e",
      "6569eff7efcb4315a78f63faa4984d50",
      "948f8b22b36d45df8152b44f0c90cae6",
      "86076fe76fd94e28980d5215a5f2c60a",
      "099634e97f5b480d85a61efbce6b9edf",
      "d424e7deecf84537b845ad43f98dea17",
      "b066f8dc2b194ae68af0aa879ae52cd9",
      "68b051ea8f6545949f9d4add28e192a4",
      "f6783c370222425b8e58a6cbc4f422d6",
      "ad7cea1796df459ab656424cd0869786",
      "0530fbee0a4a4e90ba66c631206c23c5",
      "1b6307b212ad445d9ae928624a141e12",
      "66cf27d073a345d19b075b4025bd8f93",
      "5cd5f59f777b43e2b8c76cad94ab0e64",
      "3b3fcff97261425ca670ae19d05992ca",
      "7b830b40fcfb4cefaa09542eb1813bd5",
      "ddaa610ff0d840cdab9519a84a28b30f",
      "e1cf90b66cc745768a7f39577879f7dd",
      "2593279f95bf4765b916944410ec4fdd"
     ]
    },
    "id": "5b35bf73",
    "outputId": "7bd09ee0-5bef-4dab-fea6-0a0511aadbe0"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Compute and summarize flag_age_extreme if age < 10 or > 100\n",
    "SELECT\n",
    "  COUNTIF(age < 10 OR age > 100) AS extreme_age_users,\n",
    "  COUNT(*) AS total,\n",
    "  ROUND(100*COUNTIF(age < 10 OR age > 100)/COUNT(*),2) AS pct_extreme_age_users\n",
    "FROM `netflix.users`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GpERBN6EyBxF",
   "metadata": {
    "id": "GpERBN6EyBxF"
   },
   "outputs": [],
   "source": [
    "# # EXAMPLE (from LLM) — flag_duration_anomaly (commented)\n",
    "# # SELECT\n",
    "# #   COUNTIF(duration_min < 15) AS titles_under_15m,\n",
    "# #   COUNTIF(duration_min > 8*60) AS titles_over_8h,\n",
    "# #   COUNT(*) AS total\n",
    "# # FROM `${GOOGLE_CLOUD_PROJECT}.netflix.movies`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e7869",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "e04f36a3b7ec419d80b9ff0798c79f19",
      "f0ff71371c6f445fac8c470c0a490479",
      "aafac0292867465890798c00d7b0d1e9",
      "c739863534644e98a0f6ba110234a8e3",
      "d5ae5babeebe4862839aec9aedacdf27",
      "2e6facc275034853958d167874264f3d",
      "2b8a6a64b50c45b788d7c92ef012b6f1",
      "5858d4d51c9d4f9f970fc3d94ec7f1a1",
      "e200b0f52038480cbda08243a389d5ec",
      "efd745f64db44a72afcd29ef15ea4013",
      "3383bdc417574f6da3b575a619acc092",
      "0dd70989d1df468c80c11cc99008c0c8",
      "e9fd3583076e4c4fb3becd96c01d3540",
      "282c0c6a66ac41b19c24a1c6c4bac8f6",
      "276c5459a8e54e8587c3074b1d99afc0",
      "602bf01b4ad947318a6bcc45a7fe6392",
      "932d8360867f4ffd82ecb26247c2cf51",
      "9b58deffb7db4648bc16fda100852a30",
      "1b97b6859aa4449bb3f22336e268bfb1",
      "2145e2ebae314870ad73b9cfcd6aaa41",
      "453895d0d23341c6ad6d676e43a90306",
      "e92bb1f9f92543d09f74d428898bdee8"
     ]
    },
    "id": "dd1e7869",
    "outputId": "3b16c40c-2ca1-4097-e092-f1febb4eea91"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Compute and summarize flag_duration_anomaly where duration_minutes < 15 or > 480\n",
    "SELECT\n",
    "  COUNTIF(duration_minutes < 15) AS titles_under_15m,\n",
    "  COUNTIF(duration_minutes > 480) AS titles_over_8h,\n",
    "  COUNT(*) AS total,\n",
    "  ROUND(100*COUNTIF(duration_minutes < 15 OR duration_minutes > 480)/COUNT(*),2) AS pct_duration_anomalies\n",
    "FROM `netflix.movies`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fMVCwRayBxF",
   "metadata": {
    "id": "2fMVCwRayBxF"
   },
   "source": [
    "### Verification Prompt\n",
    "Generate a single compact summary query that returns two columns per flag: `flag_name, pct_of_rows`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006fdfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207,
     "referenced_widgets": [
      "fa17428373d84c7e8aceb4181207eff2",
      "af6e395681ff43bab4cbc2897901b0fa",
      "c6bbb78019d344dfb2cdce5661960ead",
      "fae8b8880e06409ebd1b99d03e4e523c",
      "336dcfb5a24a43928436a62e4403dce7",
      "e6cfa02e29674265b998b1a852323e55",
      "e26683b9f06b4cef9fe557cd9ed38021",
      "ceaa63924f0442ab91cfc12468294f3a",
      "01ceaffa206a4dd9af98f3090f4884b4",
      "3572700e083f473d96e82eba4854ccaf",
      "afcc2646c26a47d9b11f3b14d4850048",
      "2ee12c7e152b4537a403a68852d26835",
      "29e3bc429efb41989069a39d7d902225",
      "257d45cb72fb4d769214065c4ecc8b21",
      "c344dbc03bcf4bec9695fa729f19bdca",
      "2c736528ef6f410b939e077ca5d8b302",
      "471a0571aeac4072ae7417b4ee08d80e",
      "725ca14d7cc1409c8683da098689bd98",
      "61b9504a61344245837abdc39ccfd69b",
      "d47fdbf3d975465a9f6b78a642809ab6",
      "7f56f59affba437698ecde96a358a36b",
      "db85901699b6479fbaeb18219fc11223"
     ]
    },
    "id": "f006fdfd",
    "outputId": "364eb130-55fc-4b6f-8014-406cc690c87b"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "-- Verification: Compact summary of anomaly flags (percentage of rows)\n",
    "SELECT\n",
    "  'flag_binge' AS flag_name,\n",
    "  ROUND(100*COUNTIF(watch_duration_minutes_capped > 8*60)/(COUNT(*)),2) AS pct_of_rows\n",
    "FROM `netflix.watch_history_robust`\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'flag_age_extreme' AS flag_name,\n",
    "  ROUND(100*COUNTIF(age < 10 OR age > 100)/(COUNT(*)),2) AS pct_of_rows\n",
    "FROM `netflix.users`\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'flag_duration_anomaly' AS flag_name,\n",
    "  ROUND(100*COUNTIF(duration_minutes < 15 OR duration_minutes > 480)/(COUNT(*)),2) AS pct_of_rows\n",
    "FROM `netflix.movies`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qzZUnQyryBxF",
   "metadata": {
    "id": "qzZUnQyryBxF"
   },
   "source": [
    "**Reflection:** Which anomaly flag is most common? Which would you keep as a feature and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4bea7",
   "metadata": {
    "id": "e9f4bea7"
   },
   "source": [
    "**Reflection:** Based on the anomaly flag summary, the `flag_duration_anomaly` is the most common flag, affecting 2.21% of movies. The `flag_age_extreme` affects 1.74% of users, and `flag_binge` affects 0.00% of watch sessions (after capping).\n",
    "\n",
    "Regarding which flag to keep as a feature, it depends on the specific business problem or ML task. However, the `flag_binge` (or a similar flag indicating unusually long watch sessions) could be particularly valuable as a feature for recommendation systems or user segmentation. Binge behavior can indicate high engagement or specific user preferences, which could be strong signals for predicting future behavior or tailoring content recommendations. While `flag_duration_anomaly` and `flag_age_extreme` might be useful for data cleaning or understanding data quality issues, `flag_binge` seems more directly relevant as a behavioral feature for modeling user engagement or preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eDKvePrLyBxF",
   "metadata": {
    "id": "eDKvePrLyBxF"
   },
   "source": [
    "## 6) Save & submit — What & Why\n",
    "Reproducibility: save artifacts and document decisions so others can rerun and audit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pow6VZSyyBxF",
   "metadata": {
    "id": "pow6VZSyyBxF"
   },
   "source": [
    "### Build Prompt\n",
    "Generate a checklist (Markdown) students can paste at the end:\n",
    "- Save this notebook to the team Drive.\n",
    "- Export a `.sql` file with your DQ queries and save to repo.\n",
    "- Push notebook + SQL to the **team GitHub** with a descriptive commit.\n",
    "- Add a README with your `PROJECT_ID`, `REGION`, bucket, dataset, and today’s row counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0361382",
   "metadata": {
    "id": "a0361382"
   },
   "source": [
    "## 6) Save & submit Checklist\n",
    "\n",
    "- [ ]  Save this notebook to the team Drive.\n",
    "- [ ]  Export a `.sql` file with your DQ queries and save to repo.\n",
    "- [ ]  Push notebook + SQL to the **team GitHub** with a descriptive commit.\n",
    "- [ ]  Add a README with your `${PROJECT_ID}`, `${REGION}`, bucket, dataset, and today’s row counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fMHKonySyBxF",
   "metadata": {
    "id": "fMHKonySyBxF"
   },
   "source": [
    "## Grading rubric (quick)\n",
    "- Profiling completeness (30)  \n",
    "- Cleaning policy correctness & reproducibility (40)  \n",
    "- Reflection/insight (20)  \n",
    "- Hygiene (naming, verification, idempotence) (10)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
